#!/bin/bash

# =============================================================================
# BridgeVLA è‡ªå®šä¹‰è®­ç»ƒè„šæœ¬
# ä¿®æ”¹è‡ªåŸå§‹çš„train.shï¼Œé€‚é…æ‚¨çš„ç¯å¢ƒ
# =============================================================================

echo "ğŸš€ å¼€å§‹BridgeVLAè®­ç»ƒ..."
echo "å½“å‰æ—¶é—´: $(date)"
echo "å½“å‰ç”¨æˆ·: $(whoami)"
echo "å½“å‰ç›®å½•: $(pwd)"

# =============================================================================
# ç¯å¢ƒé…ç½®éƒ¨åˆ† - è¯·æ ¹æ®æ‚¨çš„å®é™…ç¯å¢ƒä¿®æ”¹
# =============================================================================

# è®¾ç½® Hugging Face ç¼“å­˜è·¯å¾„ (æ ¹æ®æ‚¨çš„å­˜å‚¨ç©ºé—´è°ƒæ•´)
export HF_HOME="/home/lpy/BridgeVLA_dev/huggingface_cache"

# åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•
cd /home/lpy/BridgeVLA_dev/finetune

# CoppeliaSim é…ç½® (å¦‚æœä¸ä½¿ç”¨ä»¿çœŸå¯ä»¥æ³¨é‡Šæ‰)
# export COPPELIASIM_ROOT=$(pwd)/CoppeliaSim_Edu_V4_1_0_Ubuntu20_04 
# export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$COPPELIASIM_ROOT
# export QT_QPA_PLATFORM_PLUGIN_PATH=$COPPELIASIM_ROOT
# export DISPLAY=:1.0

# åˆ‡æ¢åˆ°Realç›®å½•
cd /home/lpy/BridgeVLA_dev/finetune/Real

# åˆ›å»ºå¿…è¦çš„ç›®å½•
mkdir -p logs
mkdir -p /home/lpy/BridgeVLA_dev/huggingface_cache

echo "ğŸ“‹ æ‰€æœ‰ä¼ å…¥çš„å‚æ•°ï¼š$@"

# =============================================================================
# GPU å’Œåˆ†å¸ƒå¼è®­ç»ƒé…ç½®
# =============================================================================

# è®¾ç½®å¯è§çš„GPU (æ ¹æ®æ‚¨çš„GPUæ•°é‡å’Œç¼–å·è°ƒæ•´)
# ç¤ºä¾‹ï¼šä½¿ç”¨GPU 0 (å•å¡è®­ç»ƒ)
export CUDA_VISIBLE_DEVICES=4,5,6,7

# ç¤ºä¾‹ï¼šä½¿ç”¨å¤šå¼ GPU (å¤šå¡è®­ç»ƒ)
# export CUDA_VISIBLE_DEVICES=0,1,2,3

# è°ƒè¯•é€‰é¡¹ (ç”Ÿäº§ç¯å¢ƒå¯ä»¥æ³¨é‡Šæ‰)
export TORCH_SHOW_CPP_STACKTRACES=1
# export TORCH_DISTRIBUTED_DEBUG=DETAIL  # åªåœ¨è°ƒè¯•æ—¶å¯ç”¨

# æ£€æŸ¥GPUå¯ç”¨æ€§
echo "ğŸ” æ£€æŸ¥GPUçŠ¶æ€:"
nvidia-smi --query-gpu=index,name,memory.used,memory.total --format=csv

# =============================================================================
# è®­ç»ƒå‚æ•°é…ç½®
# =============================================================================

# è·å–GPUæ•°é‡
GPU_COUNT=$(echo $CUDA_VISIBLE_DEVICES | tr ',' ' ' | wc -w)
echo "ğŸ“Š ä½¿ç”¨GPUæ•°é‡: $GPU_COUNT"

# è®¾ç½®éšæœºç«¯å£é¿å…å†²çª
MASTER_PORT=$(python3 -c "import socket; s=socket.socket(); s.bind(('', 0)); print(s.getsockname()[1]); s.close()")
echo "ğŸŒ Master Port: $MASTER_PORT"

# =============================================================================
# å¯åŠ¨è®­ç»ƒ
# =============================================================================

if [ $GPU_COUNT -eq 1 ]; then
    echo "ğŸš€ å¯åŠ¨å•GPUè®­ç»ƒ..."
    python3 train.py $@
else
    echo "ğŸš€ å¯åŠ¨å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒ..."
    torchrun --nnodes=1 \
             --node_rank=0 \
             --master_port=$MASTER_PORT \
             --nproc_per_node=$GPU_COUNT \
             train.py $@
fi

# =============================================================================
# é¢„å®šä¹‰çš„è®­ç»ƒé…ç½®ç¤ºä¾‹
# =============================================================================

# æ‚¨å¯ä»¥å–æ¶ˆæ³¨é‡Šä»¥ä¸‹ä»»ä¸€é…ç½®æ¥å¿«é€Ÿå¼€å§‹è®­ç»ƒï¼š

# 1. è°ƒè¯•æ¨¡å¼ (æœ€å°é…ç½®ï¼Œå¿«é€Ÿæµ‹è¯•)
: '
bash my_train.sh \
    --debug \
    --exp_cfg_path configs/real.yaml \
    --exp_note debug_test \
    --cameras 3rd \
    --ep_per_task 1 \
    --data_folder /home/lpy/BridgeVLA_dev/finetune/Real/data/put_code_can_on_top_shelf_with_different_rotation
'

# 2. å®Œæ•´è®­ç»ƒæ¨¡å¼
: '
bash my_train.sh \
    --exp_cfg_path configs/real.yaml \
    --exp_note my_full_training \
    --cameras 3rd \
    --ep_per_task 10 \
    --data_folder /home/lpy/BridgeVLA_dev/finetune/Real/data/put_code_can_on_top_shelf_with_different_rotation \
    --test_split_ratio 0.1 \
    --freeze_vision_tower \
    --load_pretrain \
    --pretrain_path /path/to/your/pretrained/model
'

# 3. å¤šæ•°æ®é›†è®­ç»ƒ
: '
bash my_train.sh \
    --exp_cfg_path configs/real.yaml \
    --exp_note multi_dataset_training \
    --cameras 3rd \
    --ep_per_task 15 \
    --data_folder /path/to/dataset1 /path/to/dataset2 /path/to/dataset3 \
    --test_split_ratio 0.1
'

echo "âœ… è®­ç»ƒè„šæœ¬æ‰§è¡Œå®Œæˆ!"
echo "ğŸ“ æ—¥å¿—æ–‡ä»¶ä½ç½®: logs/"
echo "ğŸ’¾ æ¨¡å‹ä¿å­˜ä½ç½®: logs/train/*/models/"
