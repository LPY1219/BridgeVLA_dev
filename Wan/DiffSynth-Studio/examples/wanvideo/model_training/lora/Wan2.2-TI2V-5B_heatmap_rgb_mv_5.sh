#!/bin/bash

# æœºå™¨1çš„CoppeliaSimé…ç½®
MACHINE1_COPPELIASIM_ROOT="/DATA/disk1/lpy/BridgeVLA_dev/finetune/CoppeliaSim_Edu_V4_1_0_Ubuntu20_04"
MACHINE1_DISPLAY=":1.0"
MACHINE1_CONDA_PATH="/home/yw/anaconda3/etc/profile.d/conda.sh"
MACHINE1_CONDA_ENV="BridgeVLA_DM"

# æœºå™¨2çš„CoppeliaSimé…ç½®ï¼ˆå¾…å¡«å†™ï¼‰
MACHINE2_COPPELIASIM_ROOT="/home/lpy/BridgeVLA_dev/finetune/CoppeliaSim_Edu_V4_1_0_Ubuntu20_04"  # TODO: å¡«å†™å½“å‰æœºå™¨çš„CoppeliaSimè·¯å¾„
MACHINE2_DISPLAY=":1.0"           # TODO: å¡«å†™å½“å‰æœºå™¨çš„DISPLAYé…ç½®
MACHINE2_CONDA_PATH="/home/lpy/anaconda3/etc/profile.d/conda.sh"  # TODO: å¡«å†™å½“å‰æœºå™¨çš„condaè·¯å¾„
MACHINE2_CONDA_ENV="BridgeVLA_DM"   # TODO: å¡«å†™å½“å‰æœºå™¨çš„condaç¯å¢ƒå

# æœºå™¨3çš„CoppeliaSimé…ç½®
MACHINE3_COPPELIASIM_ROOT="/DATA/disk0/lpy/BridgeVLA_dev/finetune/CoppeliaSim_Edu_V4_1_0_Ubuntu20_04"
MACHINE3_DISPLAY=":1.0"
MACHINE3_CONDA_PATH="/home/yw/anaconda3/etc/profile.d/conda.sh"  # å’Œmachine1ä¸€è‡´
MACHINE3_CONDA_ENV="BridgeVLA_DM"

# æœºå™¨4çš„CoppeliaSimé…ç½®
MACHINE4_COPPELIASIM_ROOT="/DATA/disk1/lpy_a100_4/BridgeVLA_dev/finetune/CoppeliaSim_Edu_V4_1_0_Ubuntu20_04"
MACHINE4_DISPLAY=":1.0"
MACHINE4_CONDA_PATH="/home/yw/anaconda3/etc/profile.d/conda.sh"  # å’Œmachine1ä¸€è‡´
MACHINE4_CONDA_ENV="BridgeVLA_DM"

# æœºå™¨5çš„CoppeliaSimé…ç½®
MACHINE5_COPPELIASIM_ROOT="/DATA/disk1/lpy_a100_1/BridgeVLA_dev/finetune/CoppeliaSim_Edu_V4_1_0_Ubuntu20_04"
MACHINE5_DISPLAY=":1.0"
MACHINE5_CONDA_PATH="/DATA/disk1/yaoliang/miniconda3/etc/profile.d/conda.sh"
MACHINE5_CONDA_ENV="BridgeVLA_DM"

# æœºå™¨6çš„CoppeliaSimé…ç½®
MACHINE6_COPPELIASIM_ROOT="/mnt/robot-rfm/user/lpy/BridgeVLA_dev/finetune/CoppeliaSim_Edu_V4_1_0_Ubuntu20_04"
MACHINE6_DISPLAY=":1.0"
MACHINE6_CONDA_PATH="/root/miniconda3/etc/profile.d/conda.sh"
MACHINE6_CONDA_ENV="BridgeVLA_DM"

# é€šè¿‡COPPELIASIM_ROOTæ£€æµ‹æœºå™¨å¹¶è®¾ç½®ç¯å¢ƒ
if [ -d "${MACHINE1_COPPELIASIM_ROOT}" ]; then
    echo "æ£€æµ‹åˆ°æœºå™¨1ï¼ˆåŸºäºCOPPELIASIM_ROOTï¼‰ï¼Œä½¿ç”¨é…ç½®1"
    CURRENT_MACHINE="machine1"
    export COPPELIASIM_ROOT="${MACHINE1_COPPELIASIM_ROOT}"
    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$COPPELIASIM_ROOT
    export QT_QPA_PLATFORM_PLUGIN_PATH=$COPPELIASIM_ROOT
    export DISPLAY="${MACHINE1_DISPLAY}"
    source "${MACHINE1_CONDA_PATH}"
    conda activate "${MACHINE1_CONDA_ENV}"
    echo "å·²è®¾ç½®æœºå™¨1çš„CoppeliaSimç¯å¢ƒå˜é‡å’Œcondaç¯å¢ƒ"
elif [ -d "${MACHINE2_COPPELIASIM_ROOT}" ]; then
    echo "æ£€æµ‹åˆ°æœºå™¨2ï¼ˆåŸºäºCOPPELIASIM_ROOTï¼‰ï¼Œä½¿ç”¨é…ç½®2"
    CURRENT_MACHINE="machine2"
    export COPPELIASIM_ROOT="${MACHINE2_COPPELIASIM_ROOT}"
    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$COPPELIASIM_ROOT
    export QT_QPA_PLATFORM_PLUGIN_PATH=$COPPELIASIM_ROOT
    export DISPLAY="${MACHINE2_DISPLAY}"
    source "${MACHINE2_CONDA_PATH}"
    conda activate "${MACHINE2_CONDA_ENV}"
    echo "å·²è®¾ç½®æœºå™¨2çš„CoppeliaSimç¯å¢ƒå˜é‡å’Œcondaç¯å¢ƒ"
elif [ -d "${MACHINE3_COPPELIASIM_ROOT}" ]; then
    echo "æ£€æµ‹åˆ°æœºå™¨3ï¼ˆåŸºäºCOPPELIASIM_ROOTï¼‰ï¼Œä½¿ç”¨é…ç½®3"
    CURRENT_MACHINE="machine3"
    export COPPELIASIM_ROOT="${MACHINE3_COPPELIASIM_ROOT}"
    export QT_QPA_PLATFORM_PLUGIN_PATH=$COPPELIASIM_ROOT
    export DISPLAY="${MACHINE3_DISPLAY}"
    source "${MACHINE3_CONDA_PATH}"
    conda activate "${MACHINE3_CONDA_ENV}"
    # ä¿®å¤CUDAåº“å†²çªï¼šä¼˜å…ˆä½¿ç”¨PyTorchè‡ªå¸¦çš„NVIDIAåº“
    export LD_LIBRARY_PATH="${CONDA_PREFIX}/lib/python3.9/site-packages/nvidia/nvjitlink/lib:${CONDA_PREFIX}/lib:${COPPELIASIM_ROOT}:${LD_LIBRARY_PATH}"
    echo "å·²è®¾ç½®æœºå™¨3çš„CoppeliaSimç¯å¢ƒå˜é‡å’Œcondaç¯å¢ƒ"
elif [ -d "${MACHINE4_COPPELIASIM_ROOT}" ]; then
    echo "æ£€æµ‹åˆ°æœºå™¨4ï¼ˆåŸºäºCOPPELIASIM_ROOTï¼‰ï¼Œä½¿ç”¨é…ç½®4"
    CURRENT_MACHINE="machine4"
    export COPPELIASIM_ROOT="${MACHINE4_COPPELIASIM_ROOT}"
    export QT_QPA_PLATFORM_PLUGIN_PATH=$COPPELIASIM_ROOT
    export DISPLAY="${MACHINE4_DISPLAY}"
    source "${MACHINE4_CONDA_PATH}"
    conda activate "${MACHINE4_CONDA_ENV}"
    # ä¿®å¤CUDAåº“å†²çªï¼šä¼˜å…ˆä½¿ç”¨PyTorchè‡ªå¸¦çš„NVIDIAåº“
    export LD_LIBRARY_PATH="${CONDA_PREFIX}/lib/python3.9/site-packages/nvidia/nvjitlink/lib:${CONDA_PREFIX}/lib:${COPPELIASIM_ROOT}:${LD_LIBRARY_PATH}"
    echo "å·²è®¾ç½®æœºå™¨4çš„CoppeliaSimç¯å¢ƒå˜é‡å’Œcondaç¯å¢ƒ"
elif [ -d "${MACHINE5_COPPELIASIM_ROOT}" ]; then
    echo "æ£€æµ‹åˆ°æœºå™¨5ï¼ˆåŸºäºCOPPELIASIM_ROOTï¼‰ï¼Œä½¿ç”¨é…ç½®5"
    CURRENT_MACHINE="machine5"
    export COPPELIASIM_ROOT="${MACHINE5_COPPELIASIM_ROOT}"
    export QT_QPA_PLATFORM_PLUGIN_PATH=$COPPELIASIM_ROOT
    export DISPLAY="${MACHINE5_DISPLAY}"
    source "${MACHINE5_CONDA_PATH}"
    conda activate "${MACHINE5_CONDA_ENV}"
    # ä¿®å¤CUDAåº“å†²çªï¼šä¼˜å…ˆä½¿ç”¨PyTorchè‡ªå¸¦çš„NVIDIAåº“
    export LD_LIBRARY_PATH="${CONDA_PREFIX}/lib/python3.9/site-packages/nvidia/nvjitlink/lib:${CONDA_PREFIX}/lib:${COPPELIASIM_ROOT}:${LD_LIBRARY_PATH}"
    echo "å·²è®¾ç½®æœºå™¨5çš„CoppeliaSimç¯å¢ƒå˜é‡å’Œcondaç¯å¢ƒ"
elif [ -d "${MACHINE6_COPPELIASIM_ROOT}" ]; then
    echo "æ£€æµ‹åˆ°æœºå™¨6ï¼ˆåŸºäºCOPPELIASIM_ROOTï¼‰ï¼Œä½¿ç”¨é…ç½®6"
    CURRENT_MACHINE="machine6"
    export COPPELIASIM_ROOT="${MACHINE6_COPPELIASIM_ROOT}"
    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$COPPELIASIM_ROOT
    export QT_QPA_PLATFORM_PLUGIN_PATH=$COPPELIASIM_ROOT
    export DISPLAY="${MACHINE6_DISPLAY}"
    source "${MACHINE6_CONDA_PATH}"
    conda activate "${MACHINE6_CONDA_ENV}"
    echo "å·²è®¾ç½®æœºå™¨6çš„CoppeliaSimç¯å¢ƒå˜é‡å’Œcondaç¯å¢ƒ"
else
    echo "é”™è¯¯ï¼šæœªæ‰¾åˆ°COPPELIASIM_ROOTè·¯å¾„"
    echo "è¯·æ£€æŸ¥ä»¥ä¸‹è·¯å¾„æ˜¯å¦å­˜åœ¨ï¼š"
    echo "  æœºå™¨1: ${MACHINE1_COPPELIASIM_ROOT}"
    echo "  æœºå™¨2: ${MACHINE2_COPPELIASIM_ROOT}"
    echo "  æœºå™¨3: ${MACHINE3_COPPELIASIM_ROOT}"
    echo "  æœºå™¨4: ${MACHINE4_COPPELIASIM_ROOT}"
    echo "  æœºå™¨5: ${MACHINE5_COPPELIASIM_ROOT}"
    echo "  æœºå™¨6: ${MACHINE6_COPPELIASIM_ROOT}"
    exit 1
fi

# å†…å­˜ä¼˜åŒ–ç¯å¢ƒå˜é‡ - æ¿€è¿›çš„40GBæ˜¾å­˜ä¼˜åŒ–
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:64,roundup_power2_divisions:32,garbage_collection_threshold:0.6,expandable_segments:True
export TOKENIZERS_PARALLELISM=false
export OMP_NUM_THREADS=2  # è¿›ä¸€æ­¥é™åˆ¶CPUçº¿ç¨‹ä»¥èŠ‚çœå†…å­˜
export CUDA_LAUNCH_BLOCKING=1  # å¯ç”¨åŒæ­¥å¯åŠ¨ä»¥è·å¾—æ›´å¥½çš„é”™è¯¯è¿½è¸ª
# export PYTORCH_NO_CUDA_MEMORY_CACHING=1  # æš‚æ—¶æ³¨é‡Šæ‰ï¼Œå¯èƒ½å½±å“DeepSpeed
export NCCL_DEBUG=WARN  # å‡å°‘NCCLè°ƒè¯•è¾“å‡º
export NCCL_TIMEOUT=3600  # å¢åŠ NCCLè¶…æ—¶æ—¶é—´åˆ°1å°æ—¶
export NCCL_IB_DISABLE=1  # ç¦ç”¨InfiniBandï¼Œä½¿ç”¨ä»¥å¤ªç½‘
export NCCL_P2P_DISABLE=1  # ç¦ç”¨P2Pé€šä¿¡ï¼Œé¿å…æŸäº›é€šä¿¡é—®é¢˜
export NCCL_TREE_THRESHOLD=0  # å¼ºåˆ¶ä½¿ç”¨æ ‘ç®—æ³•
export NCCL_ALGO=Tree  # ä½¿ç”¨æ›´ç¨³å®šçš„æ ‘ç®—æ³•
# export NCCL_SOCKET_IFNAME=eth0  # æ³¨é‡Šæ‰ï¼Œè®©NCCLè‡ªåŠ¨æ£€æµ‹ç½‘ç»œæ¥å£

# CUDAé©±åŠ¨ä¼˜åŒ–è®¾ç½®ï¼ˆè§£å†³CUDA driver erroré—®é¢˜ï¼‰
export CUDA_MODULE_LOADING=LAZY  # å»¶è¿ŸåŠ è½½CUDAæ¨¡å—
export CUDA_VISIBLE_DEVICES_ORDER=PCI_BUS_ID  # ä½¿ç”¨PCIæ€»çº¿IDé¡ºåº
export CUDA_DEVICE_ORDER=PCI_BUS_ID  # ç¡®ä¿è®¾å¤‡é¡ºåºä¸€è‡´
export CUDA_MPS_PIPE_DIRECTORY=/tmp/nvidia-mps  # è®¾ç½®MPSç®¡é“ç›®å½•
export CUDA_MPS_LOG_DIRECTORY=/tmp/nvidia-log   # è®¾ç½®MPSæ—¥å¿—ç›®å½•

# é¢å¤–çš„ç¨³å®šæ€§è®¾ç½®
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128,roundup_power2_divisions:16,garbage_collection_threshold:0.8  # æ›´ä¿å®ˆçš„å†…å­˜åˆ†é…
export TORCH_NCCL_ASYNC_ERROR_HANDLING=1  # å¯ç”¨å¼‚æ­¥é”™è¯¯å¤„ç†
export TORCH_NCCL_BLOCKING_WAIT=1  # å¯ç”¨é˜»å¡ç­‰å¾…ä»¥æé«˜ç¨³å®šæ€§
export NCCL_ASYNC_ERROR_HANDLING=1  # NCCLå¼‚æ­¥é”™è¯¯å¤„ç†

# å¯ç”¨è¯¦ç»†çš„é”™è¯¯è¿½è¸ª
export TORCH_DISTRIBUTED_DEBUG=DETAIL  # æ˜¾ç¤ºè¯¦ç»†çš„åˆ†å¸ƒå¼è®­ç»ƒé”™è¯¯ä¿¡æ¯
export TORCH_SHOW_CPP_STACKTRACES=1    # æ˜¾ç¤ºC++å †æ ˆè·Ÿè¸ª
export TORCHELASTIC_ERROR_FILE=/tmp/torch_elastic_error.json  # ä¿å­˜è¯¦ç»†é”™è¯¯åˆ°æ–‡ä»¶

# ==============================================
# é¡¹ç›®è·¯å¾„é…ç½®
# ==============================================

# æœºå™¨1çš„é¡¹ç›®è·¯å¾„é…ç½®
MACHINE1_PROJECT_ROOT="/DATA/disk1/lpy/BridgeVLA_dev/Wan/DiffSynth-Studio"
MACHINE1_DEEPSPEED_CONFIG_DIR="/DATA/disk1/lpy/BridgeVLA_dev/Wan/DiffSynth-Studio/examples/wanvideo/model_training/config"

# æœºå™¨2çš„é¡¹ç›®è·¯å¾„é…ç½®
MACHINE2_PROJECT_ROOT="/home/lpy/BridgeVLA_dev/Wan/DiffSynth-Studio"         
MACHINE2_DEEPSPEED_CONFIG_DIR="/home/lpy/BridgeVLA_dev/Wan/DiffSynth-Studio/examples/wanvideo/model_training/config" 

# æœºå™¨3çš„é¡¹ç›®è·¯å¾„é…ç½®
MACHINE3_PROJECT_ROOT="/DATA/disk0/lpy/BridgeVLA_dev/Wan/DiffSynth-Studio"
MACHINE3_DEEPSPEED_CONFIG_DIR="/DATA/disk0/lpy/BridgeVLA_dev/Wan/DiffSynth-Studio/examples/wanvideo/model_training/config"

# æœºå™¨4çš„é¡¹ç›®è·¯å¾„é…ç½®
MACHINE4_PROJECT_ROOT="/DATA/disk1/lpy_a100_4/BridgeVLA_dev/Wan/DiffSynth-Studio"
MACHINE4_DEEPSPEED_CONFIG_DIR="/DATA/disk1/lpy_a100_4/BridgeVLA_dev/Wan/DiffSynth-Studio/examples/wanvideo/model_training/config"

# æœºå™¨5çš„é¡¹ç›®è·¯å¾„é…ç½®
MACHINE5_PROJECT_ROOT="/DATA/disk1/lpy_a100_1/BridgeVLA_dev/Wan/DiffSynth-Studio"
MACHINE5_DEEPSPEED_CONFIG_DIR="/DATA/disk1/lpy_a100_1/BridgeVLA_dev/Wan/DiffSynth-Studio/examples/wanvideo/model_training/config"

# æœºå™¨6çš„é¡¹ç›®è·¯å¾„é…ç½®
MACHINE6_PROJECT_ROOT="/mnt/robot-rfm/user/lpy/BridgeVLA_dev/Wan/DiffSynth-Studio"
MACHINE6_DEEPSPEED_CONFIG_DIR="/mnt/robot-rfm/user/lpy/BridgeVLA_dev/Wan/DiffSynth-Studio/examples/wanvideo/model_training/config"

# æ ¹æ®æœºå™¨ç±»å‹è®¾ç½®é¡¹ç›®è·¯å¾„
if [ "${CURRENT_MACHINE}" = "machine1" ]; then
    PROJECT_ROOT="${MACHINE1_PROJECT_ROOT}"
    DEEPSPEED_CONFIG_DIR="${MACHINE1_DEEPSPEED_CONFIG_DIR}"
elif [ "${CURRENT_MACHINE}" = "machine2" ]; then
    PROJECT_ROOT="${MACHINE2_PROJECT_ROOT}"
    DEEPSPEED_CONFIG_DIR="${MACHINE2_DEEPSPEED_CONFIG_DIR}"
elif [ "${CURRENT_MACHINE}" = "machine3" ]; then
    PROJECT_ROOT="${MACHINE3_PROJECT_ROOT}"
    DEEPSPEED_CONFIG_DIR="${MACHINE3_DEEPSPEED_CONFIG_DIR}"
elif [ "${CURRENT_MACHINE}" = "machine4" ]; then
    PROJECT_ROOT="${MACHINE4_PROJECT_ROOT}"
    DEEPSPEED_CONFIG_DIR="${MACHINE4_DEEPSPEED_CONFIG_DIR}"
elif [ "${CURRENT_MACHINE}" = "machine5" ]; then
    PROJECT_ROOT="${MACHINE5_PROJECT_ROOT}"
    DEEPSPEED_CONFIG_DIR="${MACHINE5_DEEPSPEED_CONFIG_DIR}"
elif [ "${CURRENT_MACHINE}" = "machine6" ]; then
    PROJECT_ROOT="${MACHINE6_PROJECT_ROOT}"
    DEEPSPEED_CONFIG_DIR="${MACHINE6_DEEPSPEED_CONFIG_DIR}"
fi

# æ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•æ˜¯å¦å­˜åœ¨
if [ ! -d "${PROJECT_ROOT}" ]; then
    echo "é”™è¯¯ï¼šé¡¹ç›®æ ¹ç›®å½•ä¸å­˜åœ¨: ${PROJECT_ROOT}"
    exit 1
fi

# å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•è®¾ç½®ï¼ˆè§£å†³CUDAå¤šè¿›ç¨‹é—®é¢˜ï¼‰
export PYTHONPATH="${PROJECT_ROOT}:$PYTHONPATH"

# è®¾ç½®å·¥ä½œç›®å½•
cd "${PROJECT_ROOT}"
echo "å½“å‰å·¥ä½œç›®å½•: $(pwd)"

# ==============================================
# GPUé…ç½® - æ”¯æŒå•æœºå¤šå¡è®­ç»ƒ
# ==============================================
# 8å¼ A100è®­ç»ƒé…ç½® - æœ€å¤§åŒ–åˆ†æ•£æ¨¡å‹å‚æ•°
# export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
# NUM_GPUS=8

# å…¶ä»–å¸¸ç”¨é…ç½®ç¤ºä¾‹ï¼ˆå¤‡ç”¨ï¼‰ï¼š
export CUDA_VISIBLE_DEVICES=7; NUM_GPUS=1
# export CUDA_VISIBLE_DEVICES=0,1; NUM_GPUS=2
# export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7; NUM_GPUS=8
# export CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7; NUM_GPUS=7
# æµ‹è¯•ç”¨4ä¸ªGPUï¼ˆæ¨èå…ˆç”¨è¿™ä¸ªæ’æŸ¥é—®é¢˜ï¼‰
# export CUDA_VISIBLE_DEVICES=1,2,3,4; NUM_GPUS=4
# å¦‚æœ4ä¸ªGPUæ­£å¸¸ï¼Œå†æ”¹å›7ä¸ªGPUï¼š
# export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7; NUM_GPUS=8

# ==============================================
# æ•°æ®å’Œæ¨¡å‹è·¯å¾„é…ç½®
# ==============================================

# æœºå™¨1çš„è·¯å¾„é…ç½®
MACHINE1_HEATMAP_DATA_ROOT="/DATA/disk1/lpy/Franka_data_3zed_5/pour_filter"
MACHINE1_OUTPUT_BASE="/DATA/disk1/lpy/BridgeVLA_dev/logs/Wan/train"
MACHINE1_MODEL_BASE_PATH="/DATA/disk1/lpy/huggingface/Wan2.2-TI2V-5B-fused"

# æœºå™¨2çš„è·¯å¾„é…ç½®ï¼ˆå¾…å¡«å†™ï¼‰
MACHINE2_HEATMAP_DATA_ROOT=""    # TODO: å¡«å†™å½“å‰æœºå™¨çš„çƒ­åŠ›å›¾æ•°æ®æ ¹ç›®å½•
# MACHINE2_HEATMAP_DATA_ROOT="/data/Franka_data_3zed_2/put_red_bull_in_pink_plate"    # TODO: å¡«å†™å½“å‰æœºå™¨çš„çƒ­åŠ›å›¾æ•°æ®æ ¹ç›®å½•
MACHINE2_OUTPUT_BASE="/home/lpy/BridgeVLA_dev/logs/Wan/train"          # TODO: å¡«å†™å½“å‰æœºå™¨çš„è¾“å‡ºåŸºç¡€ç›®å½•
MACHINE2_MODEL_BASE_PATH="/data/lpy/huggingface/Wan2.2-TI2V-5B-fused"      # TODO: å¡«å†™å½“å‰æœºå™¨çš„æ¨¡å‹åŸºç¡€è·¯å¾„

# æœºå™¨3çš„è·¯å¾„é…ç½®
MACHINE3_HEATMAP_DATA_ROOT="/DATA/disk0/lpy/data/Franka_data_3zed_5/pour_filter"  # TODO: æ ¹æ®å®é™…ä»»åŠ¡ä¿®æ”¹
MACHINE3_OUTPUT_BASE="/DATA/disk0/lpy/BridgeVLA_dev/logs/Wan/train"
MACHINE3_MODEL_BASE_PATH="/DATA/disk0/lpy/huggingface/Wan2.2-TI2V-5B-fused"

# æœºå™¨4çš„è·¯å¾„é…ç½®
MACHINE4_HEATMAP_DATA_ROOT="/DATA/disk1/lpy_a100_4/data/Franka_data_3zed_5/pour_filter"  # TODO: æ ¹æ®å®é™…ä»»åŠ¡ä¿®æ”¹
MACHINE4_OUTPUT_BASE="/DATA/disk1/lpy_a100_4/BridgeVLA_dev/logs/Wan/train"
MACHINE4_MODEL_BASE_PATH="/DATA/disk1/lpy_a100_4/huggingface/Wan2.2-TI2V-5B-fused"

# æœºå™¨5çš„è·¯å¾„é…ç½®
MACHINE5_HEATMAP_DATA_ROOT="/DATA/disk1/lpy_a100_1/Franka_data_3zed_5/pour_filter"
MACHINE5_OUTPUT_BASE="/DATA/disk1/lpy_a100_1/BridgeVLA_dev/logs/Wan/train"
MACHINE5_MODEL_BASE_PATH="/DATA/disk1/lpy_a100_1/huggingface/Wan2.2-TI2V-5B-fused"

# æœºå™¨6çš„è·¯å¾„é…ç½®
MACHINE6_HEATMAP_DATA_ROOT="/mnt/robot-rfm/user/lpy/data/Franka_data_3zed_5/pour_filter"
MACHINE6_OUTPUT_BASE="/mnt/robot-rfm/user/lpy/BridgeVLA_dev/logs/Wan/train"
MACHINE6_MODEL_BASE_PATH="/mnt/robot-rfm/user/lpy/huggingface/Wan2.2-TI2V-5B-fused"

# æ ¹æ®æœºå™¨ç±»å‹è®¾ç½®è·¯å¾„
if [ "${CURRENT_MACHINE}" = "machine1" ]; then
    HEATMAP_DATA_ROOT="${MACHINE1_HEATMAP_DATA_ROOT}"
    OUTPUT_BASE="${MACHINE1_OUTPUT_BASE}"
    MODEL_BASE_PATH="${MACHINE1_MODEL_BASE_PATH}"
elif [ "${CURRENT_MACHINE}" = "machine2" ]; then
    HEATMAP_DATA_ROOT="${MACHINE2_HEATMAP_DATA_ROOT}"
    OUTPUT_BASE="${MACHINE2_OUTPUT_BASE}"
    MODEL_BASE_PATH="${MACHINE2_MODEL_BASE_PATH}"
elif [ "${CURRENT_MACHINE}" = "machine3" ]; then
    HEATMAP_DATA_ROOT="${MACHINE3_HEATMAP_DATA_ROOT}"
    OUTPUT_BASE="${MACHINE3_OUTPUT_BASE}"
    MODEL_BASE_PATH="${MACHINE3_MODEL_BASE_PATH}"
elif [ "${CURRENT_MACHINE}" = "machine4" ]; then
    HEATMAP_DATA_ROOT="${MACHINE4_HEATMAP_DATA_ROOT}"
    OUTPUT_BASE="${MACHINE4_OUTPUT_BASE}"
    MODEL_BASE_PATH="${MACHINE4_MODEL_BASE_PATH}"
elif [ "${CURRENT_MACHINE}" = "machine5" ]; then
    HEATMAP_DATA_ROOT="${MACHINE5_HEATMAP_DATA_ROOT}"
    OUTPUT_BASE="${MACHINE5_OUTPUT_BASE}"
    MODEL_BASE_PATH="${MACHINE5_MODEL_BASE_PATH}"
elif [ "${CURRENT_MACHINE}" = "machine6" ]; then
    HEATMAP_DATA_ROOT="${MACHINE6_HEATMAP_DATA_ROOT}"
    OUTPUT_BASE="${MACHINE6_OUTPUT_BASE}"
    MODEL_BASE_PATH="${MACHINE6_MODEL_BASE_PATH}"
fi

# ==============================================
# å¤šä»»åŠ¡è®­ç»ƒå’ŒTrailèŒƒå›´è¿‡æ»¤é…ç½®
# ==============================================

# å•ä»»åŠ¡è®­ç»ƒç¤ºä¾‹ï¼ˆä¿ç•™åŸæœ‰é…ç½®ï¼‰
# HEATMAP_DATA_ROOTå·²åœ¨ä¸Šé¢è®¾ç½®

# å¤šä»»åŠ¡è®­ç»ƒç¤ºä¾‹ï¼ˆç”¨æˆ·å¯ä»¥ä¿®æ”¹ä¸ºå¤šä¸ªä»»åŠ¡è·¯å¾„ï¼Œç”¨ç©ºæ ¼åˆ†éš”ï¼‰
# HEATMAP_DATA_ROOT="/data/Franka_data/task1 /data/Franka_data/task2 /data/Franka_data/task3 /data/Franka_data/task4"

# TrailèŒƒå›´è¿‡æ»¤ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨æ‰€æœ‰trailsï¼‰
TRAIL_START="1"          # èµ·å§‹trailç¼–å·ï¼Œå¦‚1è¡¨ç¤ºä»trail_1å¼€å§‹ã€‚ç•™ç©ºè¡¨ç¤ºä¸é™åˆ¶
TRAIL_END="5"            # ç»“æŸtrailç¼–å·ï¼Œå¦‚50è¡¨ç¤ºåˆ°trail_50ç»“æŸã€‚ç•™ç©ºè¡¨ç¤ºä¸é™åˆ¶
# ç¤ºä¾‹ï¼šåªä½¿ç”¨trail_1åˆ°trail_50
# TRAIL_START=1
# TRAIL_END=50


# æŒ‡å®šWanæ¨¡å‹ç±»å‹
# å¯é€‰å€¼:
#   - 5B_TI2V_RGB_HEATMAP_MV: æ ‡å‡†å¤šè§†è§’æ¨¡å¼ï¼ˆNUM_HISTORY_FRAMES=1æ—¶ä½¿ç”¨ï¼‰
#   - 5B_TI2V_RGB_HEATMAP_MV_HISTORY: å¤šå¸§å†å²æ¨¡å¼ï¼ˆNUM_HISTORY_FRAMES>1æ—¶ä½¿ç”¨ï¼‰
WAN_TYPE="5B_TI2V_RGB_HEATMAP_MV"
# çƒ­åŠ›å›¾ä¸“ç”¨å‚æ•°
SEQUENCE_LENGTH=24       # æœªæ¥å¸§åºåˆ—é•¿åº¦ # çƒ­åŠ›å›¾åºåˆ—åŠ ä¸ŠåŸå§‹å›¾åƒçš„å¾—åˆ°çš„æ€»å¸§æ•°ï¼Œå¿…é¡»é™¤ä»¥4ä½™ä¸€
STEP_INTERVAL=1           # è½¨è¿¹æ­¥é•¿é—´éš”
MIN_TRAIL_LENGTH=10       # æœ€å°è½¨è¿¹é•¿åº¦
HEATMAP_SIGMA=1.5         # é«˜æ–¯çƒ­åŠ›å›¾æ ‡å‡†å·®
COLORMAP_NAME="jet"   # colormapåç§°ï¼ˆç»Ÿä¸€ä½¿ç”¨cv2 JETï¼‰

# å†å²å¸§é…ç½® - æ§åˆ¶è¾“å…¥æ¡ä»¶å¸§æ•°é‡
# å†å²å¸§æŒ‰ç…§VAEåŸå§‹æ–¹å¼ç¼–ç ï¼šç¬¬ä¸€å¸§å•ç‹¬ç¼–ç ï¼Œåç»­æ¯4å¸§ä¸€ç»„
#
# å…è®¸çš„å†å²å¸§æ•°é‡ï¼š
#   - 1: å•å¸§æ¡ä»¶ï¼ˆå‘åå…¼å®¹ï¼‰â†’ 1ä¸ªæ¡ä»¶latent
#   - 2: ä¸¤å¸§åˆ†åˆ«å•ç‹¬ç¼–ç  â†’ 2ä¸ªæ¡ä»¶latent
#   - 1+4N (5,9,13...): ç¬¬ä¸€å¸§å•ç‹¬ + åç»­æ¯4å¸§ä¸€ç»„ â†’ (1+N)ä¸ªæ¡ä»¶latent
#
# ç¤ºä¾‹ï¼š
#   NUM_HISTORY_FRAMES=1  â†’ num_condition_latents=1
#   NUM_HISTORY_FRAMES=2  â†’ num_condition_latents=2  (æ¯å¸§å•ç‹¬ç¼–ç )
#   NUM_HISTORY_FRAMES=5  â†’ num_condition_latents=2  (1å¸§ + 4å¸§)
#   NUM_HISTORY_FRAMES=9  â†’ num_condition_latents=3  (1å¸§ + 4å¸§ + 4å¸§)
#
# âš ï¸ é‡è¦ï¼šå½“ NUM_HISTORY_FRAMES>1 æ—¶ï¼Œå¿…é¡»å°† WAN_TYPE è®¾ç½®ä¸º 5B_TI2V_RGB_HEATMAP_MV_HISTORY
NUM_HISTORY_FRAMES=1     # å†å²å¸§æ•°é‡ï¼Œå¿…é¡»ä¸º 1, 2, æˆ– 1+4N (5,9,13...)

# éªŒè¯ NUM_HISTORY_FRAMES çš„åˆæ³•æ€§
# å¿…é¡»æ˜¯ 1, 2, æˆ– 1+4N (å³ (n-1) % 4 == 0 å½“ n > 2)
is_valid_history_frames=false
if [ ${NUM_HISTORY_FRAMES} -eq 1 ]; then
    is_valid_history_frames=true
elif [ ${NUM_HISTORY_FRAMES} -eq 2 ]; then
    is_valid_history_frames=true
elif [ ${NUM_HISTORY_FRAMES} -gt 2 ]; then
    # æ£€æŸ¥æ˜¯å¦ä¸º 1+4N å½¢å¼
    remainder=$(( (${NUM_HISTORY_FRAMES} - 1) % 4 ))
    if [ ${remainder} -eq 0 ]; then
        is_valid_history_frames=true
    fi
fi

if [ "${is_valid_history_frames}" != "true" ]; then
    echo "ERROR: NUM_HISTORY_FRAMES=${NUM_HISTORY_FRAMES} is invalid!"
    echo "       Allowed values: 1, 2, or 1+4N (5, 9, 13, 17, ...)"
    echo "       This ensures proper VAE encoding: first frame alone, then groups of 4"
    exit 1
fi

# éªŒè¯ WAN_TYPE å’Œ NUM_HISTORY_FRAMES çš„ä¸€è‡´æ€§ï¼ˆåŒå‘æ£€æµ‹ï¼‰
# è§„åˆ™1: NUM_HISTORY_FRAMES > 1 å¿…é¡»ä½¿ç”¨ 5B_TI2V_RGB_HEATMAP_MV_HISTORY
if [ ${NUM_HISTORY_FRAMES} -gt 1 ] && [ "${WAN_TYPE}" != "5B_TI2V_RGB_HEATMAP_MV_HISTORY" ]; then
    echo "ERROR: NUM_HISTORY_FRAMES=${NUM_HISTORY_FRAMES} > 1, but WAN_TYPE=${WAN_TYPE}"
    echo "       When using multi-frame history (NUM_HISTORY_FRAMES > 1), you MUST set:"
    echo "       WAN_TYPE=\"5B_TI2V_RGB_HEATMAP_MV_HISTORY\""
    exit 1
fi
# è§„åˆ™2: ä½¿ç”¨ 5B_TI2V_RGB_HEATMAP_MV_HISTORY å¿…é¡»è®¾ç½® NUM_HISTORY_FRAMES > 1
if [ ${NUM_HISTORY_FRAMES} -eq 1 ] && [ "${WAN_TYPE}" == "5B_TI2V_RGB_HEATMAP_MV_HISTORY" ]; then
    echo "ERROR: WAN_TYPE=5B_TI2V_RGB_HEATMAP_MV_HISTORY, but NUM_HISTORY_FRAMES=${NUM_HISTORY_FRAMES}"
    echo "       When using 5B_TI2V_RGB_HEATMAP_MV_HISTORY, you MUST set NUM_HISTORY_FRAMES > 1"
    echo "       If you want single-frame mode, use WAN_TYPE=\"5B_TI2V_RGB_HEATMAP_MV\""
    exit 1
fi

# å›¾åƒå’Œè®­ç»ƒå‚æ•° - 256x256åˆ†è¾¨ç‡ä»¥èŠ‚çœæ˜¾å­˜
HEIGHT=256
WIDTH=256
NUM_FRAMES=${SEQUENCE_LENGTH}
# ä¼˜åŒ–æ–¹æ¡ˆï¼šå‡å°‘DATASET_REPEATï¼Œå¢åŠ EPOCHSè·å¾—æ›´ç²¾ç»†çš„æ§åˆ¶
DATASET_REPEAT=1                     # ä¸é‡å¤æ•°æ®é›†
LEARNING_RATE=1e-4
NUM_EPOCHS=100                       # æœ€å¤§è®­ç»ƒepochæ•°
SAVE_EPOCHS_INTERVAL=10               # æ¯éš”å¤šå°‘ä¸ªepochä¿å­˜ä¸€æ¬¡æ¨¡å‹ï¼ˆ0è¡¨ç¤ºåªåœ¨æœ€åä¿å­˜ï¼‰

# å¤šGPUè®­ç»ƒå‚æ•°è°ƒæ•´ - 2å¼ GPUé…ç½®
TRAIN_BATCH_SIZE_PER_GPU=1            # æ¯å¼ GPUçš„æ‰¹æ¬¡å¤§å°ä¿æŒä¸º1ï¼ŒWanåªæ”¯æŒè¿™æ ·
GRADIENT_ACCUMULATION_STEPS=4           # å¢åŠ æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ä»¥ä¿æŒç›¸åŒçš„æœ‰æ•ˆæ‰¹æ¬¡å¤§å°
EFFECTIVE_BATCH_SIZE=$((NUM_GPUS * TRAIN_BATCH_SIZE_PER_GPU * GRADIENT_ACCUMULATION_STEPS))
echo "Total effective batch size: ${EFFECTIVE_BATCH_SIZE}"

# æ˜¾å­˜ä¼˜åŒ–å‚æ•° - ç›®æ ‡40GBä»¥ä¸‹
DATASET_NUM_WORKERS=0                   # æ•°æ®åŠ è½½çº¿ç¨‹æ•°ï¼ˆè®¾ä¸º0é¿å…CUDAå¤šè¿›ç¨‹é—®é¢˜ï¼‰
USE_GRADIENT_CHECKPOINTING=false        # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰
# æ˜¾å­˜ä¼˜åŒ–å·²ç§»é™¤ï¼Œç”±DeepSpeedå¤„ç†
MIXED_PRECISION="bf16"                  # ä½¿ç”¨bf16æ··åˆç²¾åº¦
DATALOADER_PIN_MEMORY=false             # å…³é—­pin memoryä»¥èŠ‚çœæ˜¾å­˜
PREFETCH_FACTOR=2                       # å‡å°‘æ•°æ®é¢„å–å› å­ä»¥èŠ‚çœæ˜¾å­˜
# LoRAå‚æ•°
LORA_RANK=32
# ç§»é™¤patch_embeddingå’Œhead.headï¼Œæ”¹ä¸ºå…¨é‡è®­ç»ƒ
LORA_TARGET_MODULES="q,k,v,o,ffn.0,ffn.2"

# Dual Headæ¨¡å¼ - æ˜¯å¦ä½¿ç”¨åŒheadï¼ˆRGBå’ŒHeatmapå„è‡ªç‹¬ç«‹çš„headï¼‰
USE_DUAL_HEAD=true  # è®¾ç½®ä¸ºtrueå¯ç”¨åŒheadæ¨¡å¼ï¼Œfalseä½¿ç”¨å•headæ¨¡å¼

# ==============================================
# æŸå¤±æƒé‡é…ç½® - RGB Loss Weight
# ==============================================
# æ§åˆ¶RGB losså’ŒHeatmap lossçš„æƒé‡åˆ†é…
# æ€»loss = RGB_LOSS_WEIGHT * loss_rgb + (1 - RGB_LOSS_WEIGHT) * loss_heatmap
# å–å€¼èŒƒå›´: 0.0 ~ 1.0
#   - 1.0: åªä½¿ç”¨RGB loss
#   - 0.5: RGBå’ŒHeatmap losså„å ä¸€åŠï¼ˆé»˜è®¤ï¼‰
#   - 0.0: åªä½¿ç”¨Heatmap loss
RGB_LOSS_WEIGHT=0.08

# ==============================================
# é«˜çº§è®­ç»ƒå‚æ•° - Modulation å’Œ Norm è§£å†»æ§åˆ¶
# ==============================================
# âš ï¸  IMPORTANT: æ§åˆ¶æ˜¯å¦è§£å†» modulation å’Œ norm å‚æ•°ä»¥è·å¾—æ›´å¥½çš„é€‚åº”æ€§
#
# ä»€ä¹ˆæ—¶å€™è®¾ç½®ä¸º trueï¼š
# - è®­ç»ƒå…¨æ–°æ¨¡å‹æ—¶ï¼ˆæ¨èï¼‰
# - æƒ³è¦æœ€å¤§åŒ–ä»»åŠ¡é€‚åº”æ€§æ—¶
# - ä¸åœ¨æ„ä¸æ—§ checkpoint çš„å…¼å®¹æ€§æ—¶
#
# ä»€ä¹ˆæ—¶å€™è®¾ç½®ä¸º falseï¼ˆé»˜è®¤ï¼‰ï¼š
# - æµ‹è¯•å·²æœ‰çš„æ—§ checkpoint æ—¶ï¼ˆå‘åå…¼å®¹ï¼‰
# - ä»æ—§çš„é¢„è®­ç»ƒæ¨¡å‹ç»§ç»­è®­ç»ƒæ—¶ï¼ˆä¿æŒä¸€è‡´æ€§ï¼‰
#
# å½±å“çš„å‚æ•°ï¼š
# - modulation: AdaLN è°ƒåˆ¶å‚æ•° (~0.55Mï¼Œå½±å“å¤§ï¼‰
# - mvs_attn.norm_q/norm_k: å¤šè§†è§’ RMSNorm (~0.18M)
#
UNFREEZE_MODULATION_AND_NORMS=true  # è®¾ç½®ä¸º true è®­ç»ƒæ–°æ¨¡å‹ï¼Œfalse ä¿æŒå‘åå…¼å®¹

# ==============================================
# é¢„è®­ç»ƒæ¨¡å‹åŠ è½½é…ç½® (ç”¨äºä»é¢„è®­ç»ƒcheckpointç»§ç»­finetune)
# ==============================================
# æ˜¯å¦åŠ è½½é¢„è®­ç»ƒçš„checkpointè¿›è¡Œfinetune
LOAD_PRETRAINED_CHECKPOINT=False # è®¾ç½®ä¸ºtrueå¯ç”¨é¢„è®­ç»ƒæƒé‡åŠ è½½
# ç”Ÿæˆæ—¶é—´æˆ³ç›®å½•å
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
NAME="test_h20e_${LOAD_PRETRAINED_CHECKPOINT}_history_${NUM_HISTORY_FRAMES}_seq_${SEQUENCE_LENGTH}_new_projection"
OUTPUT_PATH="${OUTPUT_BASE}/Wan2.2-TI2V-5B_heatmap_rgb_lora/5_trajectory_pour_3camera_${NAME}_rgb_loss_${RGB_LOSS_WEIGHT}/${TIMESTAMP}"

# é¢„è®­ç»ƒcheckpointè·¯å¾„é…ç½®ï¼ˆå„æœºå™¨çš„è·¯å¾„ï¼‰
# æœºå™¨1çš„é¢„è®­ç»ƒcheckpointè·¯å¾„
MACHINE1_PRETRAINED_CHECKPOINT="/DATA/disk1/lpy/BridgeVLA_dev/logs/Wan/pretrain/Wan2.2-TI2V-5B_mvtrack_pretrain_unfreeze_modulation_true_epoch-15.safetensors"
# æœºå™¨2çš„é¢„è®­ç»ƒcheckpointè·¯å¾„
MACHINE2_PRETRAINED_CHECKPOINT="/home/lpy/BridgeVLA_dev/logs/Wan/pretrain/Wan2.2-TI2V-5B_mvtrack_pretrain_unfreeze_modulation_true/20251208_045615/epoch-15.safetensors"
# æœºå™¨3çš„é¢„è®­ç»ƒcheckpointè·¯å¾„
ACHINE3_PRETRAINED_CHECKPOINT="/DATA/disk0/lpy/BridgeVLA_dev/logs/Wan/train/Wan2.2-TI2V-5B_heatmap_rgb_lora/8_trajectory_cook_5_3camera_pour_filter_pretrain_False_history_1_seq_48_new_projection_rgb_loss_1/20260105_203050/epoch-99.safetensors"
# æœºå™¨4çš„é¢„è®­ç»ƒcheckpointè·¯å¾„
MACHINE4_PRETRAINED_CHECKPOINT="/DATA/disk1/lpy_a100_4/BridgeVLA_dev/logs/Wan/pretrain/Wan2.2-TI2V-5B_mvtrack_pretrain_unfreeze_modulation_true_epoch-15.safetensors"

# æœºå™¨5çš„é¢„è®­ç»ƒcheckpointè·¯å¾„
MACHINE5_PRETRAINED_CHECKPOINT="/DATA/disk1/lpy_a100_1/BridgeVLA_dev/logs/Wan/pretrain/Wan2.2-TI2V-5B_mvtrack_pretrain_unfreeze_modulation_true_epoch-15.safetensors"

# æœºå™¨6çš„é¢„è®­ç»ƒcheckpointè·¯å¾„
MACHINE6_PRETRAINED_CHECKPOINT="/mnt/robot-rfm/user/lpy/BridgeVLA_dev/logs/Wan/pretrain/Wan2.2-TI2V-5B_mvtrack_pretrain_unfreeze_modulation_true_epoch-15.safetensors"

# æ ¹æ®æœºå™¨ç±»å‹è®¾ç½®é¢„è®­ç»ƒcheckpointè·¯å¾„
if [ "${CURRENT_MACHINE}" = "machine1" ]; then
    PRETRAINED_CHECKPOINT="${MACHINE1_PRETRAINED_CHECKPOINT}"
elif [ "${CURRENT_MACHINE}" = "machine2" ]; then
    PRETRAINED_CHECKPOINT="${MACHINE2_PRETRAINED_CHECKPOINT}"
elif [ "${CURRENT_MACHINE}" = "machine3" ]; then
    PRETRAINED_CHECKPOINT="${MACHINE3_PRETRAINED_CHECKPOINT}"
elif [ "${CURRENT_MACHINE}" = "machine4" ]; then
    PRETRAINED_CHECKPOINT="${MACHINE4_PRETRAINED_CHECKPOINT}"
elif [ "${CURRENT_MACHINE}" = "machine5" ]; then
    PRETRAINED_CHECKPOINT="${MACHINE5_PRETRAINED_CHECKPOINT}"
elif [ "${CURRENT_MACHINE}" = "machine6" ]; then
    PRETRAINED_CHECKPOINT="${MACHINE6_PRETRAINED_CHECKPOINT}"
fi

# ç‚¹äº‘é…ç½®
# true: ä½¿ç”¨ä¸‰ä¸ªç›¸æœºæ‹¼æ¥çš„ç‚¹äº‘
# false: åªä½¿ç”¨ç›¸æœº1çš„ç‚¹äº‘
USE_MERGED_POINTCLOUD=false

# æŠ•å½±æ¨¡å¼é…ç½®
# true: ä½¿ç”¨ä¸åŒçš„æŠ•å½±æ–¹å¼ï¼ˆbase_multi_view_dataset_with_rot_grip_3cam_different_projection.pyï¼‰
# false: ä½¿ç”¨é»˜è®¤æŠ•å½±æ–¹å¼ï¼ˆbase_multi_view_dataset_with_rot_grip_3cam.pyï¼‰
USE_DIFFERENT_PROJECTION=true

# æ•°æ®å¢å¼ºå‚æ•°
# SCENE_BOUNDS="0,-0.7,-0.05,0.8,0.7,0.65"
# SCENE_BOUNDS="0,-0.55,-0.05,0.8,0.45,0.6"
# SCENE_BOUNDS="0,-0.65,-0.05,0.8,0.55,0.75"
SCENE_BOUNDS="-0.1,-0.5,-0.1,0.9,0.5,0.9"
TRANSFORM_AUG_XYZ="0.1,0.1,0.1"
TRANSFORM_AUG_RPY="5.0,5.0,5.0"  

# SwanLabé…ç½®å‚æ•°
ENABLE_SWANLAB=true                         # æ˜¯å¦å¯ç”¨SwanLabè®°å½•
SWANLAB_API_KEY="h1x6LOLp5qGLTfsPuB7Qw"    # SwanLab APIå¯†é’¥
SWANLAB_PROJECT="Wan2.2-TI2V-5B_heatmap_rgb_lora_pour"  # SwanLabé¡¹ç›®åç§°
SWANLAB_EXPERIMENT="${NAME}-$(date +%Y%m%d-%H%M%S)"  # SwanLabå®éªŒåç§°ï¼ˆæ·»åŠ æ—¶é—´æˆ³ï¼‰
DEBUG_MODE=false                           # è°ƒè¯•æ¨¡å¼ï¼ˆä¸ºtrueæ—¶ç¦ç”¨SwanLabï¼‰

echo "================================================================"
echo "HEATMAP SEQUENCE TRAINING FOR Wan2.2-TI2V-5B_heatmap_rgb_lora"
echo "================================================================"
echo "å½“å‰ä½¿ç”¨æœºå™¨: ${CURRENT_MACHINE}"
echo "é¡¹ç›®æ ¹ç›®å½•: ${PROJECT_ROOT}"
echo "æ•°æ®æ ¹ç›®å½•: ${HEATMAP_DATA_ROOT}"
echo "æ¨¡å‹è·¯å¾„: ${MODEL_BASE_PATH}"
echo "è¾“å‡ºè·¯å¾„: ${OUTPUT_PATH}"
echo "----------------------------------------------------------------"
echo "é¢„è®­ç»ƒé…ç½®:"
echo "  åŠ è½½é¢„è®­ç»ƒæƒé‡: ${LOAD_PRETRAINED_CHECKPOINT}"
if [ "${LOAD_PRETRAINED_CHECKPOINT}" = "true" ]; then
    echo "  é¢„è®­ç»ƒcheckpoint: ${PRETRAINED_CHECKPOINT}"
fi
echo "----------------------------------------------------------------"
echo "è®­ç»ƒå‚æ•°:"
echo "  åºåˆ—é•¿åº¦: ${SEQUENCE_LENGTH}"
echo "  å›¾åƒå°ºå¯¸: ${HEIGHT}x${WIDTH}"
echo "  å­¦ä¹ ç‡: ${LEARNING_RATE}"
echo "  LoRA rank: ${LORA_RANK}"
echo "  LoRAç›®æ ‡æ¨¡å—: ${LORA_TARGET_MODULES}"
echo "  åŒHeadæ¨¡å¼: ${USE_DUAL_HEAD}"
echo "  RGB Lossæƒé‡: ${RGB_LOSS_WEIGHT}"
echo "  è§£å†»Modulationå’ŒNorms: ${UNFREEZE_MODULATION_AND_NORMS}"
echo "  ç‚¹äº‘èåˆæ¨¡å¼: ${USE_MERGED_POINTCLOUD}"
echo "  ä¸åŒæŠ•å½±æ¨¡å¼: ${USE_DIFFERENT_PROJECTION}"
echo "  GPUæ•°é‡: ${NUM_GPUS}"
echo "  æ¯GPUæ‰¹æ¬¡å¤§å°: ${TRAIN_BATCH_SIZE_PER_GPU}"
echo "  æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: ${EFFECTIVE_BATCH_SIZE}"
echo "  æ•°æ®åŠ è½½çº¿ç¨‹æ•°: ${DATASET_NUM_WORKERS}"
echo "  æ··åˆç²¾åº¦: ${MIXED_PRECISION}"
echo "  æ¢¯åº¦æ£€æŸ¥ç‚¹: ${USE_GRADIENT_CHECKPOINTING}"
echo "  ä¿å­˜é—´éš”: æ¯${SAVE_EPOCHS_INTERVAL}ä¸ªepochä¿å­˜ä¸€æ¬¡"
echo "  å†å²å¸§æ•°é‡: ${NUM_HISTORY_FRAMES}"
echo "  SwanLabå¯ç”¨: ${ENABLE_SWANLAB}"
echo "  è°ƒè¯•æ¨¡å¼: ${DEBUG_MODE}"
echo "================================================================"

# ==============================================
# è·¯å¾„éªŒè¯
# ==============================================

# æ£€æŸ¥æ•°æ®ç›®å½•
if [ ! -d "${HEATMAP_DATA_ROOT}" ]; then
    echo "é”™è¯¯ï¼šæ•°æ®ç›®å½•ä¸å­˜åœ¨: ${HEATMAP_DATA_ROOT}"
    echo "è¯·æ£€æŸ¥æ•°æ®è·¯å¾„å¹¶é‡è¯•ã€‚"
    exit 1
fi

# æ£€æŸ¥æ¨¡å‹ç›®å½•
if [ ! -d "${MODEL_BASE_PATH}" ]; then
    echo "é”™è¯¯ï¼šæ¨¡å‹ç›®å½•ä¸å­˜åœ¨: ${MODEL_BASE_PATH}"
    echo "è¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„å¹¶é‡è¯•ã€‚"
    exit 1
fi

# æ£€æŸ¥é¢„è®­ç»ƒcheckpointè·¯å¾„ï¼ˆå¦‚æœå¯ç”¨ï¼‰
if [ "${LOAD_PRETRAINED_CHECKPOINT}" = "true" ]; then
    if [ ! -f "${PRETRAINED_CHECKPOINT}" ]; then
        echo "é”™è¯¯ï¼šé¢„è®­ç»ƒcheckpointæ–‡ä»¶ä¸å­˜åœ¨: ${PRETRAINED_CHECKPOINT}"
        echo "è¯·æ£€æŸ¥é¢„è®­ç»ƒcheckpointè·¯å¾„å¹¶é‡è¯•ï¼Œæˆ–è®¾ç½® LOAD_PRETRAINED_CHECKPOINT=false"
        exit 1
    fi
    echo "âœ“ é¢„è®­ç»ƒcheckpointéªŒè¯é€šè¿‡: ${PRETRAINED_CHECKPOINT}"
fi

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p "${OUTPUT_PATH}"
echo "è¾“å‡ºç›®å½•å·²åˆ›å»º: ${OUTPUT_PATH}"

# ================================================================
# å•é˜¶æ®µè®­ç»ƒ
# ================================================================
echo "================================================================"
echo "STARTING HEATMAP TRAINING"
echo "================================================================"

# æ ‡å‡†å¤šGPUè®­ç»ƒ
echo "ğŸ”§ Using standard multi-GPU training"

accelerate launch \
  --num_processes=${NUM_GPUS} \
  --num_machines=1 \
  --mixed_precision=${MIXED_PRECISION} \
  --main_process_port=29500 \
  examples/wanvideo/model_training/heatmap_train_mv.py \
  --heatmap_data_root ${HEATMAP_DATA_ROOT} \
  $(if [ -n "${TRAIL_START}" ]; then echo "--trail_start ${TRAIL_START}"; fi) \
  $(if [ -n "${TRAIL_END}" ]; then echo "--trail_end ${TRAIL_END}"; fi) \
  --sequence_length ${SEQUENCE_LENGTH} \
  --step_interval ${STEP_INTERVAL} \
  --min_trail_length ${MIN_TRAIL_LENGTH} \
  --heatmap_sigma ${HEATMAP_SIGMA} \
  --colormap_name "${COLORMAP_NAME}" \
  --scene_bounds="${SCENE_BOUNDS}" \
  --transform_augmentation_xyz="${TRANSFORM_AUG_XYZ}" \
  --transform_augmentation_rpy="${TRANSFORM_AUG_RPY}" \
  --height ${HEIGHT} \
  --width ${WIDTH} \
  --num_frames ${NUM_FRAMES} \
  --dataset_repeat ${DATASET_REPEAT} \
  --wan_type ${WAN_TYPE} \
  --model_paths '[
    [
        "'${MODEL_BASE_PATH}'/diffusion_pytorch_model-00001-of-00003.safetensors",
        "'${MODEL_BASE_PATH}'/diffusion_pytorch_model-00002-of-00003.safetensors",
        "'${MODEL_BASE_PATH}'/diffusion_pytorch_model-00003-of-00003.safetensors"
    ],
    "'${MODEL_BASE_PATH}'/models_t5_umt5-xxl-enc-bf16.pth",
    "'${MODEL_BASE_PATH}'/Wan2.2_VAE.pth"
    ]' \
  --learning_rate ${LEARNING_RATE} \
  --num_epochs ${NUM_EPOCHS} \
  --save_epochs_interval ${SAVE_EPOCHS_INTERVAL} \
  --remove_prefix_in_ckpt "pipe.dit." \
  --output_path "${OUTPUT_PATH}" \
  --lora_base_model "dit" \
  --lora_target_modules "${LORA_TARGET_MODULES}" \
  --lora_rank ${LORA_RANK} \
  $(if [ "${LOAD_PRETRAINED_CHECKPOINT}" = "true" ]; then echo "--lora_checkpoint ${PRETRAINED_CHECKPOINT}"; fi) \
  --extra_inputs "input_image,input_image_rgb,input_video_rgb" \
  --train_batch_size ${TRAIN_BATCH_SIZE_PER_GPU} \
  --gradient_accumulation_steps ${GRADIENT_ACCUMULATION_STEPS} \
  --dataset_num_workers ${DATASET_NUM_WORKERS} \
  $(if [ "${USE_GRADIENT_CHECKPOINTING}" = "true" ]; then echo "--use_gradient_checkpointing"; fi) \
  $(if [ "${USE_DUAL_HEAD}" = "true" ]; then echo "--use_dual_head"; fi) \
  --rgb_loss_weight ${RGB_LOSS_WEIGHT} \
  $(if [ "${UNFREEZE_MODULATION_AND_NORMS}" = "true" ]; then echo "--unfreeze_modulation_and_norms"; fi) \
  $(if [ "${USE_MERGED_POINTCLOUD}" = "true" ]; then echo "--use_merged_pointcloud"; fi) \
  $(if [ "${USE_DIFFERENT_PROJECTION}" = "true" ]; then echo "--use_different_projection"; fi) \
  --num_history_frames ${NUM_HISTORY_FRAMES} \
  --find_unused_parameters \
  --dataloader_pin_memory false \
  --save_steps 0 \
  --logging_steps 10 \
  --max_grad_norm 1.0 \
  --warmup_steps 100 \
  $(if [ "${DEBUG_MODE}" = "true" ]; then echo "--debug_mode"; fi) \
  $(if [ "${ENABLE_SWANLAB}" = "true" ]; then echo "--enable_swanlab"; fi) \
  --swanlab_api_key "${SWANLAB_API_KEY}" \
  --swanlab_project "${SWANLAB_PROJECT}" \
  --swanlab_experiment "${SWANLAB_EXPERIMENT}"

#   --model_paths '[
#     [
#         "'${MODEL_BASE_PATH}'/diffusion_pytorch_model-00001-of-00003.safetensors",
#         "'${MODEL_BASE_PATH}'/diffusion_pytorch_model-00002-of-00003.safetensors",
#         "'${MODEL_BASE_PATH}'/diffusion_pytorch_model-00003-of-00003.safetensors"
#     ],
#     "'${MODEL_BASE_PATH}'/models_t5_umt5-xxl-enc-bf16.pth",
#     "'${MODEL_BASE_PATH}'/Wan2.2_VAE.pth"
#     ]' \


#   --model_paths '[
#     [
#         "'${MODEL_BASE_PATH}'/diffusion_pytorch_model-00001-of-00003-bf16.safetensors",
#         "'${MODEL_BASE_PATH}'/diffusion_pytorch_model-00002-of-00003-bf16.safetensors",
#         "'${MODEL_BASE_PATH}'/diffusion_pytorch_model-00003-of-00003-bf16.safetensors"
#     ],
#     "'${MODEL_BASE_PATH}'/models_t5_umt5-xxl-enc-bf16.pth",
#     "'${MODEL_BASE_PATH}'/Wan2.2_VAE.pth"
#     ]' \

echo "================================================================"
echo "Training completed!"
echo "Output saved to: ${OUTPUT_PATH}"
echo "================================================================"